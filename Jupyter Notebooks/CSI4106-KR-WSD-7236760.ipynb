{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Notebook #7</center>\n",
    "<center>Name: NamChi Nguyen</center>\n",
    "<center>Student ID: 7236760</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge representation and similarity \n",
    "### Grounding (Word-Sense Disambiguation) to WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4106 Artificial Intelligence  \n",
    "Fall 2018  \n",
    "Caroline BarriÃ¨re\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, first, you will explore Wordnet, a lexical semantic network, in which knowledge is organized by interrelated synsets (groups of synonyms).  Second, you will attempt Word-Sense Disambiguation (WSD), using simple Lesk-like algorithm which compares BOWs (bag-of-words).  \n",
    "\n",
    "This notebook uses the same package NLTK as we used in the last notebook. We will also reuse some knowledge from the previous notebook (tokenization, lemmatization, POS tagging), so make sure to do the NLP Pipeline notebook before this one.\n",
    "\n",
    "*As you now have more experience, this notebook requires that you write more code by yourself than the previous ones.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***HOMEWORK***:  \n",
    "Go through the notebook by running each cell, one at a time. Look for (**TO DO**) for the tasks that you need to perform.  \n",
    "Make sure you *sign* (type your name) the notebook at the end. Once you're done, submit your notebook.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import nltk, and wordnet\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Exploring Wordnet**  \n",
    "\n",
    "Let's first explore a bit the wordnet interface within nltk.  \n",
    "You can also look a the [WordNet interface description](http://www.nltk.org/howto/wordnet.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('paper.n.01'), Synset('composition.n.08'), Synset('newspaper.n.01'), Synset('paper.n.04'), Synset('paper.n.05'), Synset('newspaper.n.02'), Synset('newspaper.n.03'), Synset('paper.v.01'), Synset('wallpaper.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# a synset is a concept associated with a set of synonyms\n",
    "\n",
    "paperSenses = wordnet.synsets('paper')\n",
    "print(paperSenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there are 9 senses of paper, 7 nouns and 2 verbs.  The word displayed is the most representative word for each sense.  \n",
    "\n",
    "You can try other words.  I recommend that you also perform the same search [online](http://wordnetweb.princeton.edu/perl/webwn) to better understand the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the basic information in each synset.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to print the basic information\n",
    "\n",
    "def printBasicSynsetInfo(d):\n",
    "    print(\"SynLemmas\")\n",
    "    print(d.lemmas())\n",
    "    print(\"Synonyms\")\n",
    "    synonyms = [l.name() for l in d.lemmas()]\n",
    "    print(synonyms)\n",
    "    print(\"Definition\")\n",
    "    print(d.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sense 0]\n",
      "SynLemmas\n",
      "[Lemma('paper.n.01.paper')]\n",
      "Synonyms\n",
      "['paper']\n",
      "Definition\n",
      "a material made of cellulose pulp derived mainly from wood or rags or certain grasses\n",
      "\n",
      "[Sense 1]\n",
      "SynLemmas\n",
      "[Lemma('composition.n.08.composition'), Lemma('composition.n.08.paper'), Lemma('composition.n.08.report'), Lemma('composition.n.08.theme')]\n",
      "Synonyms\n",
      "['composition', 'paper', 'report', 'theme']\n",
      "Definition\n",
      "an essay (especially one written as an assignment)\n",
      "\n",
      "[Sense 2]\n",
      "SynLemmas\n",
      "[Lemma('newspaper.n.01.newspaper'), Lemma('newspaper.n.01.paper')]\n",
      "Synonyms\n",
      "['newspaper', 'paper']\n",
      "Definition\n",
      "a daily or weekly publication on folded sheets; contains news and articles and advertisements\n",
      "\n",
      "[Sense 3]\n",
      "SynLemmas\n",
      "[Lemma('paper.n.04.paper')]\n",
      "Synonyms\n",
      "['paper']\n",
      "Definition\n",
      "a medium for written communication\n",
      "\n",
      "[Sense 4]\n",
      "SynLemmas\n",
      "[Lemma('paper.n.05.paper')]\n",
      "Synonyms\n",
      "['paper']\n",
      "Definition\n",
      "a scholarly article describing the results of observations or stating hypotheses\n",
      "\n",
      "[Sense 5]\n",
      "SynLemmas\n",
      "[Lemma('newspaper.n.02.newspaper'), Lemma('newspaper.n.02.paper'), Lemma('newspaper.n.02.newspaper_publisher')]\n",
      "Synonyms\n",
      "['newspaper', 'paper', 'newspaper_publisher']\n",
      "Definition\n",
      "a business firm that publishes newspapers\n",
      "\n",
      "[Sense 6]\n",
      "SynLemmas\n",
      "[Lemma('newspaper.n.03.newspaper'), Lemma('newspaper.n.03.paper')]\n",
      "Synonyms\n",
      "['newspaper', 'paper']\n",
      "Definition\n",
      "the physical object that is the product of a newspaper publisher\n",
      "\n",
      "[Sense 7]\n",
      "SynLemmas\n",
      "[Lemma('paper.v.01.paper')]\n",
      "Synonyms\n",
      "['paper']\n",
      "Definition\n",
      "cover with paper\n",
      "\n",
      "[Sense 8]\n",
      "SynLemmas\n",
      "[Lemma('wallpaper.v.01.wallpaper'), Lemma('wallpaper.v.01.paper')]\n",
      "Synonyms\n",
      "['wallpaper', 'paper']\n",
      "Definition\n",
      "cover with wallpaper\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can print the information for each sense of \"paper\"\n",
    "\n",
    "for i in range(len(paperSenses)):\n",
    "    print(\"[Sense \" + str(i) + \"]\")\n",
    "    printBasicSynsetInfo(paperSenses[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rich taxonomy has been manually developed in Wordnet, making it a rich resource.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO-DO : Q1)** Choose two words, and write code to print the taxonomic information for all senses of those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to print the basic information, receives a synset\n",
    "\n",
    "def printTaxonomyInfo(d):\n",
    "    synonyms = [l.name() for l in d.lemmas()]\n",
    "    print(synonyms)\n",
    "    print(\"Hypernyms:\")\n",
    "    print(d.hypernyms())\n",
    "    print(\"Hyponyms:\")\n",
    "    print(d.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sense 0]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('publication.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('appointment_book.n.01'), Synset('authority.n.07'), Synset('bestiary.n.01'), Synset('booklet.n.01'), Synset('catalog.n.01'), Synset('catechism.n.02'), Synset('copybook.n.01'), Synset('curiosa.n.01'), Synset('formulary.n.01'), Synset('phrase_book.n.01'), Synset('playbook.n.02'), Synset('pop-up_book.n.01'), Synset('prayer_book.n.01'), Synset('reference_book.n.01'), Synset('review_copy.n.01'), Synset('songbook.n.01'), Synset('storybook.n.01'), Synset('textbook.n.01'), Synset('tome.n.01'), Synset('trade_book.n.01'), Synset('workbook.n.01'), Synset('yearbook.n.01')]\n",
      "\n",
      "[Sense 1]\n",
      "['book', 'volume']\n",
      "Hypernyms:\n",
      "[Synset('product.n.02')]\n",
      "Hyponyms:\n",
      "[Synset('album.n.02'), Synset('coffee-table_book.n.01'), Synset('folio.n.03'), Synset('hardback.n.01'), Synset('journal.n.04'), Synset('notebook.n.01'), Synset('novel.n.02'), Synset('order_book.n.02'), Synset('paperback_book.n.01'), Synset('picture_book.n.01'), Synset('sketchbook.n.01')]\n",
      "\n",
      "[Sense 2]\n",
      "['record', 'record_book', 'book']\n",
      "Hypernyms:\n",
      "[Synset('fact.n.02')]\n",
      "Hyponyms:\n",
      "[Synset('card.n.08'), Synset('logbook.n.01'), Synset('won-lost_record.n.01')]\n",
      "\n",
      "[Sense 3]\n",
      "['script', 'book', 'playscript']\n",
      "Hypernyms:\n",
      "[Synset('dramatic_composition.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('continuity.n.02'), Synset('dialogue.n.02'), Synset('libretto.n.01'), Synset('promptbook.n.01'), Synset('scenario.n.01'), Synset('screenplay.n.01'), Synset('shooting_script.n.01')]\n",
      "\n",
      "[Sense 4]\n",
      "['ledger', 'leger', 'account_book', 'book_of_account', 'book']\n",
      "Hypernyms:\n",
      "[Synset('record.n.07')]\n",
      "Hyponyms:\n",
      "[Synset('cost_ledger.n.01'), Synset('daybook.n.01'), Synset('general_ledger.n.01'), Synset('subsidiary_ledger.n.01')]\n",
      "\n",
      "[Sense 5]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('collection.n.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 6]\n",
      "['book', 'rule_book']\n",
      "Hypernyms:\n",
      "[Synset('collection.n.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 7]\n",
      "['Koran', 'Quran', \"al-Qur'an\", 'Book']\n",
      "Hypernyms:\n",
      "[]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 8]\n",
      "['Bible', 'Christian_Bible', 'Book', 'Good_Book', 'Holy_Scripture', 'Holy_Writ', 'Scripture', 'Word_of_God', 'Word']\n",
      "Hypernyms:\n",
      "[Synset('sacred_text.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('family_bible.n.01')]\n",
      "\n",
      "[Sense 9]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('section.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('epistle.n.02')]\n",
      "\n",
      "[Sense 10]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('product.n.02')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 11]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('schedule.v.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 12]\n",
      "['reserve', 'hold', 'book']\n",
      "Hypernyms:\n",
      "[Synset('request.v.01')]\n",
      "Hyponyms:\n",
      "[Synset('keep_open.v.01')]\n",
      "\n",
      "[Sense 13]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('record.v.01')]\n",
      "Hyponyms:\n",
      "[Synset('ticket.v.01')]\n",
      "\n",
      "[Sense 14]\n",
      "['book']\n",
      "Hypernyms:\n",
      "[Synset('register.v.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "\n",
      "[Sense 0]\n",
      "['ring']\n",
      "Hypernyms:\n",
      "[Synset('sound.n.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 1]\n",
      "['ring', 'halo', 'annulus', 'doughnut', 'anchor_ring']\n",
      "Hypernyms:\n",
      "[Synset('toroid.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('fairy_ring.n.01')]\n",
      "\n",
      "[Sense 2]\n",
      "['hoop', 'ring']\n",
      "Hypernyms:\n",
      "[Synset('band.n.07')]\n",
      "Hyponyms:\n",
      "[Synset('carabiner.n.01'), Synset('collar.n.04'), Synset('curtain_ring.n.01'), Synset('key_ring.n.01'), Synset('napkin_ring.n.01'), Synset('nose_ring.n.01'), Synset('rim.n.02'), Synset('rim.n.03'), Synset('tire.n.01'), Synset('towel_ring.n.01')]\n",
      "\n",
      "[Sense 3]\n",
      "['closed_chain', 'ring']\n",
      "Hypernyms:\n",
      "[Synset('chain.n.02')]\n",
      "Hyponyms:\n",
      "[Synset('heterocyclic_ring.n.01')]\n",
      "\n",
      "[Sense 4]\n",
      "['gang', 'pack', 'ring', 'mob']\n",
      "Hypernyms:\n",
      "[Synset('association.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('nest.n.04'), Synset('youth_gang.n.01')]\n",
      "\n",
      "[Sense 5]\n",
      "['ring', 'ringing', 'tintinnabulation']\n",
      "Hypernyms:\n",
      "[Synset('sound.n.04')]\n",
      "Hyponyms:\n",
      "[Synset('bell_ringing.n.01')]\n",
      "\n",
      "[Sense 6]\n",
      "['ring']\n",
      "Hypernyms:\n",
      "[Synset('platform.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('boxing_ring.n.01'), Synset('sumo_ring.n.01'), Synset('wrestling_ring.n.01')]\n",
      "\n",
      "[Sense 7]\n",
      "['ring', 'band']\n",
      "Hypernyms:\n",
      "[Synset('jewelry.n.01')]\n",
      "Hyponyms:\n",
      "[Synset('annulet.n.03'), Synset('engagement_ring.n.01'), Synset('mourning_ring.n.01'), Synset('ringlet.n.03'), Synset('signet_ring.n.01'), Synset('wedding_ring.n.01')]\n",
      "\n",
      "[Sense 8]\n",
      "['band', 'ring']\n",
      "Hypernyms:\n",
      "[Synset('strip.n.02')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n",
      "[Sense 9]\n",
      "['ring', 'peal']\n",
      "Hypernyms:\n",
      "[Synset('sound.v.02')]\n",
      "Hyponyms:\n",
      "[Synset('ding.v.01'), Synset('knell.v.01'), Synset('peal.v.01'), Synset('tintinnabulate.v.01')]\n",
      "\n",
      "[Sense 10]\n",
      "['resound', 'echo', 'ring', 'reverberate']\n",
      "Hypernyms:\n",
      "[Synset('sound.v.02')]\n",
      "Hyponyms:\n",
      "[Synset('bong.v.01'), Synset('consonate.v.01'), Synset('reecho.v.01'), Synset('reecho.v.02')]\n",
      "\n",
      "[Sense 11]\n",
      "['ring', 'knell']\n",
      "Hypernyms:\n",
      "[Synset('sound.v.06')]\n",
      "Hyponyms:\n",
      "[Synset('toll.v.01')]\n",
      "\n",
      "[Sense 12]\n",
      "['call', 'telephone', 'call_up', 'phone', 'ring']\n",
      "Hypernyms:\n",
      "[Synset('telecommunicate.v.01')]\n",
      "Hyponyms:\n",
      "[Synset('call_in.v.05'), Synset('cell_phone.v.01')]\n",
      "\n",
      "[Sense 13]\n",
      "['surround', 'environ', 'ring', 'skirt', 'border']\n",
      "Hypernyms:\n",
      "[Synset('touch.v.05')]\n",
      "Hyponyms:\n",
      "[Synset('cloister.v.01'), Synset('cloister.v.02'), Synset('enclose.v.03'), Synset('fringe.v.02'), Synset('girdle.v.02'), Synset('hem_in.v.01')]\n",
      "\n",
      "[Sense 14]\n",
      "['ring', 'band']\n",
      "Hypernyms:\n",
      "[Synset('attach.v.01')]\n",
      "Hyponyms:\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1 - ANSWER\n",
    "# We can print the taxonomy information for each sense of a word X\n",
    "\n",
    "# Word #1\n",
    "bookSenses = wordnet.synsets('book')\n",
    "for i in range(len(bookSenses)):\n",
    "    print(\"[Sense \" + str(i) + \"]\")\n",
    "    printTaxonomyInfo(bookSenses[i])\n",
    "    print()\n",
    "\n",
    "print()\n",
    "\n",
    "# Word #2\n",
    "ringSenses = wordnet.synsets('ring')\n",
    "for i in range(len(ringSenses)):\n",
    "    print(\"[Sense \" + str(i) + \"]\")\n",
    "    printTaxonomyInfo(ringSenses[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Word-Sense Disambiguation.**  \n",
    "\n",
    "Let's now implement a simple modified Lesk algorithm for WSD.  \n",
    "The idea is to compare the sentence containing the ambiguous word W to all the definitions of W and choose the most similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Step 1) Create a BOW (bag of words) for each definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need the tokenizer\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small method to return the set of words found in a text\n",
    "# we can exclude some words\n",
    "\n",
    "def bow(text, excluded = None):\n",
    "    text = text.replace(\"_\", \" \") # the compound nouns in wordnet text have _\n",
    "    tokens = word_tokenize(text)\n",
    "    setTokens = set(tokens)\n",
    "    if excluded != None:\n",
    "        if (excluded in setTokens):\n",
    "            setTokens.remove(excluded)\n",
    "    return setTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'There', 'food', 'is', 'lot', 'the', 'on', 'a'}\n",
      "{'researchers', 'by', 'many', 'excellent', 'He', 'wrote', 'referred', 'conference', 'an'}\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "print(bow(\"There is a lot of food on the table\", excluded='table'))\n",
    "print(bow(\"He wrote an excellent conference paper referred by many researchers\", excluded='paper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make BOWs for all the senses in a received word\n",
    "# exclude from the BOW, the word being defined\n",
    "\n",
    "def makeDefBOWs(testWord):\n",
    "    synsets = wordnet.synsets(testWord)\n",
    "    defs = [s.definition() for s in synsets]\n",
    "    bows = [bow(d, excluded=testWord) for d in defs]\n",
    "    return bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'small', 'any', 'compartment'}\n",
      "{'animals', 'of', 'life', 'exist', 'as', 'basic', 'or', 'the', 'tissues', ';', 'unit', 'they', 'units', 'form', 'plants', ')', 'monads', 'may', 'independent', '(', 'structural', 'organisms', 'biology', 'and', 'all', 'colonies', 'in', 'functional', 'higher'}\n",
      "{'device', 'result', 'current', 'of', 'reaction', 'chemical', 'as', 'electric', 'that', 'the', 'an', 'a', 'delivers'}\n",
      "{'movement', 'serving', 'unit', 'of', 'political', 'as', 'part', 'the', 'or', 'nucleus', 'small', 'larger', 'a'}\n",
      "{',', 'each', 'area', 'radiotelephone', 'divided', 'short-range', 'use', 'with', 'own', 'mobile', 'into', 'in', 'transmitter/receiver', 'for', 'sections', 'its', 'hand-held', 'an', 'a', 'small'}\n",
      "{'which', 'nun', 'lives', 'room', 'monk', 'in', 'or', 'small', 'a'}\n",
      "{'kept', 'room', 'is', 'where', 'prisoner', 'a'}\n"
     ]
    }
   ],
   "source": [
    "# try with different words, look at the resulting info\n",
    "\n",
    "testWord = \"cell\" # bank, course, paper, ...\n",
    "defBOWs = makeDefBOWs(testWord)\n",
    "    \n",
    "print(*defBOWs, sep=\"\\n\")  # to print a list on separate lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Step 2) Create a method to compare BOWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're interested in the size of the intersection between the BOWs\n",
    "# If you wish to see the words in common to understand the results, uncomment the prints\n",
    "\n",
    "def bowOverlap(bow1, bow2):\n",
    "    #print(bow1)\n",
    "    #print(bow2)\n",
    "    print(bow1.intersection(bow2))\n",
    "    return len(bow1.intersection(bow2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO-DO: Q2)** Implement the (Step 3) of the algorithm.  The (Step 3) consist in comparing the BOW of a test sentence (let's call it our context C) containing an ambiguous word (X) to the BOWs of all the senses of the X.  To do Step 3, you need to complete the method below which receives a word X, as well as the text C in which X occurs.  The method should return the synsets with largest common BOWs with X.  Notice that there could be more than one maximum, so your method should return all synsets with maximum intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 - ANSWER\n",
    "\n",
    "# method receives a word and its context\n",
    "# returns all the synsets with maximum overlap\n",
    "\n",
    "def findMostProbableSense(word, context):\n",
    "    bows = makeDefBOWs(word)\n",
    "    textBOW = bow(context)\n",
    "    max_overlap = 0\n",
    "    max_synsets = [] #list of synsets  \n",
    "    olaps = [] #list of overlap indices\n",
    "  \n",
    "    # find senses with max overlap\n",
    "    senses = wordnet.synsets(word)\n",
    "    for i in range(len(senses)):\n",
    "        overlap = bowOverlap(bows[i], textBOW) \n",
    "        olaps.append(overlap) # Keep track of overlap indices if there's more than 1 max found\n",
    "                \n",
    "        # Print statements for verifying\n",
    "        print(\"Overlap: \",overlap)\n",
    "        print(\"BOWS: \",bows[i])\n",
    "        print(\"textBOW: \", textBOW, \"\\n\")\n",
    "        \n",
    "        if overlap > max_overlap:        \n",
    "            max_overlap = overlap\n",
    "    \n",
    "    # Add all synsets w/ max intersection        \n",
    "    for j in range(len(olaps)):\n",
    "        if max_overlap == olaps[j]:\n",
    "            max_synsets.append(senses[j]) \n",
    "            \n",
    "    return max_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your method should return the chosen senses for the example below.  We will test your method using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'small', 'any', 'compartment'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "{'in'}\n",
      "Overlap:  1\n",
      "BOWS:  {'animals', 'of', 'life', 'exist', 'as', 'basic', 'or', 'the', 'tissues', ';', 'unit', 'they', 'units', 'form', 'plants', ')', 'monads', 'may', 'independent', '(', 'structural', 'organisms', 'biology', 'and', 'all', 'colonies', 'in', 'functional', 'higher'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'device', 'result', 'current', 'of', 'reaction', 'chemical', 'as', 'electric', 'that', 'the', 'an', 'a', 'delivers'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'movement', 'serving', 'unit', 'of', 'political', 'as', 'part', 'the', 'or', 'nucleus', 'small', 'larger', 'a'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "{'in', 'for'}\n",
      "Overlap:  2\n",
      "BOWS:  {',', 'each', 'area', 'radiotelephone', 'divided', 'short-range', 'use', 'with', 'own', 'mobile', 'into', 'in', 'transmitter/receiver', 'for', 'sections', 'its', 'hand-held', 'an', 'a', 'small'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "{'in'}\n",
      "Overlap:  1\n",
      "BOWS:  {'which', 'nun', 'lives', 'room', 'monk', 'in', 'or', 'small', 'a'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'kept', 'room', 'is', 'where', 'prisoner', 'a'}\n",
      "textBOW:  {'lived', 'many', 'this', 'He', 'cell', 'in', '.', 'for', 'years', 'prison'} \n",
      "\n",
      "SynLemmas\n",
      "[Lemma('cellular_telephone.n.01.cellular_telephone'), Lemma('cellular_telephone.n.01.cellular_phone'), Lemma('cellular_telephone.n.01.cellphone'), Lemma('cellular_telephone.n.01.cell'), Lemma('cellular_telephone.n.01.mobile_phone')]\n",
      "Synonyms\n",
      "['cellular_telephone', 'cellular_phone', 'cellphone', 'cell', 'mobile_phone']\n",
      "Definition\n",
      "a hand-held mobile radiotelephone for use in an area divided into small sections, each with its own short-range transmitter/receiver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the BOWs of the senses with the overlap, and the chosen sense(s)\n",
    "# You can try with various words and sentences\n",
    "\n",
    "testWord = \"cell\"\n",
    "testSentence = \"He lived in this prison cell for many years.\" \n",
    "\n",
    "####  CALL TO YOUR METHOD RECEIVING THE WORD AND ITS CONTEXT\n",
    "chosenSynsets = findMostProbableSense(testWord, testSentence)  \n",
    "\n",
    "# print all the definitions of the most probable senses\n",
    "for s in chosenSynsets:\n",
    "    printBasicSynsetInfo(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO-DO: Q3)** What do you notice? With the example above for \"cell\", what are the words making the BOWs look similar?  Are these significant words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q3-ANSWER*  \n",
    "The prepositions 'in' and 'for' are matched with the intersection choosing a definition that is inaccurate with the context. These words aren't significant and don't give any meaning. The best sense should be the last definition: \"a room where a prisoner is kept\" since prison and prisoner are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO-DO: Q4)  Refining our BOWs**\n",
    "\n",
    "**Exploring variations:**\n",
    "1. What if you lowercase everything?\n",
    "2. What if you apply lemmatisation on all words in the BOWs?\n",
    "3. What if you focus on only the NOUNS in the BOWs?\n",
    "\n",
    "(hint) Go back to your notebook NLP pipeline for questions (2) use the lemmatizer and (3) perform POS tagging on the sentences. \n",
    "\n",
    "For your answer (code to write):  \n",
    "\n",
    "a) First complete the BOW method below in which I've added parameters to possibly activate the lowercase, the lemmatization and the POS tagging.   \n",
    "b) Add a few tests to see if your BOW works.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\viet_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Q4 - ANSWER - part a)\n",
    "\n",
    "# The parameters possibly ACTIVATE lowercase, lemmatization, and keeping only Nouns in BOWs.\n",
    "\n",
    "# nltk contains a method to obtain the part-of-speech of each token\n",
    "# Download the wordnet resource\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.ADV  # just use as default, for ADV the lemmatizer doesn't change anything \n",
    "\n",
    "    \n",
    "# refine the method with parameters\n",
    "def bow(text, excluded = None, lowercase = False, lemmatize=False, nounsOnly=False):\n",
    "    \n",
    "    text = text.replace(\"_\", \" \") # the compound nouns in wordnet text have _\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "    # Continue with the options to deal with the various cases (lemmatized T/F, nounsOnly T/F)\n",
    "    if lemmatize:\n",
    "        lemmas = [wnl.lemmatize(t) for t in word_tokenize(text)]\n",
    "        tokens = lemmas\n",
    "    \n",
    "    if nounsOnly:\n",
    "        nouns = [] # list of nouns\n",
    "        posTokens = nltk.pos_tag(word_tokenize(text))\n",
    "        wordnet_tags = [get_wordnet_pos(p[1]) for p in posTokens]        \n",
    "        posLemmas = [wnl.lemmatize(t,w) for t,w in zip(word_tokenize(text),wordnet_tags)]\n",
    "\n",
    "        for i in range(len(wordnet_tags)):\n",
    "            if wordnet_tags[i] == 'n':\n",
    "                nouns.append(posLemmas[i])\n",
    "        tokens = nouns\n",
    "    \n",
    "    setTokens = set(tokens)\n",
    "    if excluded != None:\n",
    "        if (excluded in setTokens):\n",
    "            setTokens.remove(excluded)\n",
    "    return setTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'food', 'lot'}\n",
      "{'She', 'her', 'friend', 'went', 'with', 'to', 'the'}\n",
      "{'lunch'}\n"
     ]
    }
   ],
   "source": [
    "# Q4 - ANSWER - part b)\n",
    "\n",
    "# TEST YOUR METHOD \n",
    "print(bow(\"There is a lot of food on the table\", excluded='table', lowercase=True, lemmatize=True, nounsOnly=True))\n",
    "\n",
    "# Your example 1 - Lemmatization only\n",
    "print(bow(\"She went to the play with her friend\", excluded='play', lowercase=False, lemmatize=True, nounsOnly=False))\n",
    "\n",
    "# Your example 2 - Nouns only\n",
    "print(bow(\"They took a break from studying to eat lunch\", excluded='break', lowercase=False, lemmatize=False, nounsOnly=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO-DO: Q5)** TESTING BOW VARIATIONS IN LESK-LIKE DISAMBIGUATION\n",
    "\n",
    "a) Redo the method makeDefBOW and findMostProbableSense to use the new parameters.  \n",
    "\n",
    "b) Generate three example cases and test your disambiguation strategy programmed above.  An example case contains an ambiguous word (e.g. bank) and a sentence in which that word must be disambiguated (e.g. He sat on the bank throwing rocks in the water.).  \n",
    "\n",
    "c) For your examples, which filtering seems to work better (with/without lemmatization, with/without focus only on nouns)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 - ANSWER - part a)\n",
    "\n",
    "# add the parameters to makeBOW as well, same default\n",
    "def makeDefBOWs(testWord, lowercase=False, lemmatize=False, nounsOnly=False):\n",
    "    synsets = wordnet.synsets(testWord)\n",
    "    defs = [s.definition() for s in synsets]\n",
    "    bows = [bow(d, excluded=testWord, lowercase=lowercase, lemmatize=lemmatize, nounsOnly=nounsOnly) for d in defs]\n",
    "    return bows\n",
    "   \n",
    "\n",
    "def findMostProbableSense(word, text, lowercase=False, lemmatize=False, nounsOnly=False):\n",
    "    bows = makeDefBOWs(word, lowercase, lemmatize, nounsOnly)\n",
    "    textBOW = bow(text, excluded=word, lowercase=lowercase, lemmatize=lemmatize, nounsOnly=nounsOnly)\n",
    "    max_overlap = 0\n",
    "    max_synsets = [] #list of synsets  \n",
    "    olaps = [] #list of overlap indices\n",
    "  \n",
    "    # find senses with max overlap\n",
    "    senses = wordnet.synsets(word)\n",
    "    for i in range(len(senses)):\n",
    "        overlap = bowOverlap(bows[i], textBOW) \n",
    "        olaps.append(overlap) # Keep track of overlap indices if there's more than 1 max found\n",
    "                \n",
    "        # Print statements for verifying\n",
    "        print(\"Overlap: \",overlap)\n",
    "        print(\"BOWS: \",bows[i])\n",
    "        print(\"textBOW: \", textBOW, \"\\n\")\n",
    "        \n",
    "        if overlap > max_overlap:        \n",
    "            max_overlap = overlap\n",
    "    \n",
    "    # Add all synsets w/ max intersection        \n",
    "    for j in range(len(olaps)):\n",
    "        if max_overlap == olaps[j]:\n",
    "            max_synsets.append(senses[j]) \n",
    "            \n",
    "    return max_synsets\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'set', 'row', 'data', 'column'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'furniture', 'piece', 'leg', 'top'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'furniture', 'piece', 'tableware', 'meal'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'tableland', 'edge'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'game', 'company', 'people', 'meal'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "{'food'}\n",
      "Overlap:  1\n",
      "BOWS:  {'food', 'meal'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'time'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'enter', 'arrange', 'form'}\n",
      "textBOW:  {'food', 'lot'} \n",
      "\n",
      "SynLemmas\n",
      "[Lemma('board.n.04.board'), Lemma('board.n.04.table')]\n",
      "Synonyms\n",
      "['board', 'table']\n",
      "Definition\n",
      "food or meals in general\n",
      "\n",
      "Ex 1. Lemmatization only\n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'something', 'indication', 'of', 'visible', 'clue', 'ha', 'immediately', 'perceptible', '(', 'that', 'not', ')', 'a', 'apparent', 'happened'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'display', 'public', 'of', 'message', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'gesture', 'a'}\n",
      "Overlap:  2\n",
      "BOWS:  {'action', 'gesture', 'message', 'or', 'nonverbal', 'any', 'that', 'encodes', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'which', 'can', 'posted', 'board', 'be', 'displaying', 'advertisement', 'on', 'structure', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'the'}\n",
      "Overlap:  1\n",
      "BOWS:  {'which', 'of', 'area', 'divided', 'into', 'equal', 'astrology', '(', '12', 'zodiac', 'is', 'the', ')', 'one'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'the', 'a'}\n",
      "Overlap:  2\n",
      "BOWS:  {'disease', 'of', 'disorder', 'presence', 'a', 'evidence', 'or', '(', 'any', 'the', ')', 'medicine', 'objective'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'the', 'a'}\n",
      "Overlap:  2\n",
      "BOWS:  {'charge', 'having', 'and', 'negative', 'electric', 'pole', 'distinction', '(', 'indicated', 'the', 'between', 'an', 'a', 'positive', ')'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'indicating', 'important', 'thing', 'come', 'event', 'to', 'experienced', 'is', 'that', 'an', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'gesture', 'language', 'a'}\n",
      "Overlap:  3\n",
      "BOWS:  {'of', 'gesture', 'language', 'part', 'is', 'that', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'which', 'linguistic', 'unit', 'signified', 'to', 'fundamental', 'linking', 'that', 'is', 'signifier', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'indicating', 'quantity', 'character', 'relation', 'between', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'with', ';', 'name', 'write', '(', 'signature', \"'s\", ')', 'on', 'one', 'mark'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'obligation', ',', 'responsibility', 'and', 'approve', 'assent', 'or', 'express'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {'engaged', 'by', 'be', 'written', 'agreement', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'agreement', 'written', 'by', 'engage'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'non-verbally', 'by', 'and', 'communicate', 'signal', 'or', 'silently'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'a'}\n",
      "Overlap:  1\n",
      "BOWS:  {',', 'place', 'road', 'along', 'a'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'in', 'language'}\n",
      "Overlap:  2\n",
      "BOWS:  {'in', 'language', 'communicate'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'in', 'the', 'for'}\n",
      "Overlap:  3\n",
      "BOWS:  {'of', 'god', 'someone', 'on', 'to', 'make', 'in', 'call', 'for', 'cross', 'over', 'consecrate', 'the', 'order', 'protection', ';'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "{'the', 'deaf', 'language'}\n",
      "Overlap:  3\n",
      "BOWS:  {'deaf', 'of', 'language', 'used', 'the'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'in', '.', 'hello', 'for', 'the', 'made', 'a'} \n",
      "\n",
      "SynLemmas\n",
      "[Lemma('sign.n.09.sign')]\n",
      "Synonyms\n",
      "['sign']\n",
      "Definition\n",
      "a gesture that is part of a sign language\n",
      "SynLemmas\n",
      "[Lemma('bless.v.03.bless'), Lemma('bless.v.03.sign')]\n",
      "Synonyms\n",
      "['bless', 'sign']\n",
      "Definition\n",
      "make the sign of the cross over someone in order to call on God for protection; consecrate\n",
      "SynLemmas\n",
      "[Lemma('gestural.s.01.gestural'), Lemma('gestural.s.01.sign'), Lemma('gestural.s.01.signed'), Lemma('gestural.s.01.sign-language')]\n",
      "Synonyms\n",
      "['gestural', 'sign', 'signed', 'sign-language']\n",
      "Definition\n",
      "used of the language of the deaf\n",
      "\n",
      "Ex 2. Nouns only\n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'something', 'indication', 'clue'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'display', 'message'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'gesture'}\n",
      "Overlap:  1\n",
      "BOWS:  {'action', 'gesture', 'message'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'structure', 'board', 'advertisement'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'zodiac', 'area', 'astrology'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'disease', 'disorder', 'presence', 'evidence', 'medicine'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'distinction', 'charge', 'pole'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'thing', 'event'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'gesture', 'language'}\n",
      "Overlap:  2\n",
      "BOWS:  {'gesture', 'language', 'part'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'signifier', 'unit'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'quantity', 'character', 'relation'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'name', 'signature', 'mark'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'assent', 'obligation', 'approve', 'responsibility'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'agreement'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'agreement', 'engage'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'signal', 'communicate'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'road', 'place'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'language'}\n",
      "Overlap:  1\n",
      "BOWS:  {'language', 'communicate'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'god', 'someone', 'cross', 'consecrate', 'order', 'protection'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'language', 'deaf'}\n",
      "Overlap:  2\n",
      "BOWS:  {'language', 'deaf'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "SynLemmas\n",
      "[Lemma('sign.n.09.sign')]\n",
      "Synonyms\n",
      "['sign']\n",
      "Definition\n",
      "a gesture that is part of a sign language\n",
      "SynLemmas\n",
      "[Lemma('gestural.s.01.gestural'), Lemma('gestural.s.01.sign'), Lemma('gestural.s.01.signed'), Lemma('gestural.s.01.sign-language')]\n",
      "Synonyms\n",
      "['gestural', 'sign', 'signed', 'sign-language']\n",
      "Definition\n",
      "used of the language of the deaf\n",
      "\n",
      "Ex 3. Lemmatization & nouns only\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'something', 'indication', 'clue'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'display', 'message'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'gesture'}\n",
      "Overlap:  1\n",
      "BOWS:  {'action', 'gesture', 'message'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'structure', 'board', 'advertisement'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'zodiac', 'area', 'astrology'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'disease', 'disorder', 'presence', 'evidence', 'medicine'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'distinction', 'charge', 'pole'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'thing', 'event'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'gesture', 'language'}\n",
      "Overlap:  2\n",
      "BOWS:  {'gesture', 'language', 'part'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'signifier', 'unit'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'quantity', 'character', 'relation'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'name', 'signature', 'mark'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'assent', 'obligation', 'approve', 'responsibility'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'agreement'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'agreement', 'engage'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'signal', 'communicate'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'road', 'place'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'language'}\n",
      "Overlap:  1\n",
      "BOWS:  {'language', 'communicate'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "set()\n",
      "Overlap:  0\n",
      "BOWS:  {'god', 'someone', 'cross', 'consecrate', 'order', 'protection'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "{'language', 'deaf'}\n",
      "Overlap:  2\n",
      "BOWS:  {'language', 'deaf'}\n",
      "textBOW:  {'deaf', 'gesture', 'language', 'girl', 'hello'} \n",
      "\n",
      "SynLemmas\n",
      "[Lemma('sign.n.09.sign')]\n",
      "Synonyms\n",
      "['sign']\n",
      "Definition\n",
      "a gesture that is part of a sign language\n",
      "SynLemmas\n",
      "[Lemma('gestural.s.01.gestural'), Lemma('gestural.s.01.sign'), Lemma('gestural.s.01.signed'), Lemma('gestural.s.01.sign-language')]\n",
      "Synonyms\n",
      "['gestural', 'sign', 'signed', 'sign-language']\n",
      "Definition\n",
      "used of the language of the deaf\n"
     ]
    }
   ],
   "source": [
    "# Q5 - ANSWER - part b)\n",
    "testWord = \"table\"\n",
    "testSentence = \"There is a lot of food on the table.\"\n",
    "\n",
    "chosenSynsets = findMostProbableSense(testWord, testSentence, lowercase=True, lemmatize=True, nounsOnly=True)  \n",
    "\n",
    "# print all the definitions of the most probable senses\n",
    "for s in chosenSynsets:\n",
    "    printBasicSynsetInfo(s)\n",
    "\n",
    "    \n",
    "# Your example 1 - with lemmatization only, without only nouns\n",
    "print(\"\\nEx 1. Lemmatization only\\n\")\n",
    "\n",
    "testWord_1 = \"sign\"\n",
    "testSentence_1 = \"The deaf girl made a gesture for hello in sign language.\"\n",
    "\n",
    "chosenSynsets_1 = findMostProbableSense(testWord_1, testSentence_1, lowercase=True, lemmatize=True, nounsOnly=False)  \n",
    "for s in chosenSynsets_1:\n",
    "    printBasicSynsetInfo(s)\n",
    "    \n",
    "# Your example 2 - without lemmatization, with only nouns\n",
    "print(\"\\nEx 2. Nouns only\\n\")\n",
    "chosenSynsets_2 = findMostProbableSense(testWord_1, testSentence_1, lowercase=True, lemmatize=False, nounsOnly=True)  \n",
    "for s in chosenSynsets_2:\n",
    "    printBasicSynsetInfo(s) \n",
    "    \n",
    "# Your example 3 - with lemmatization and only nouns\n",
    "print(\"\\nEx 3. Lemmatization & nouns only\\n\")\n",
    "chosenSynsets_3 = findMostProbableSense(testWord_1, testSentence_1, lowercase=True, lemmatize=True, nounsOnly=True)\n",
    "for s in chosenSynsets_3:\n",
    "    printBasicSynsetInfo(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q5 - ANSWER - part c)*  \n",
    "Ambiguous word used: sign  \n",
    "In a sentence: \"The deaf girl made a gesture for hello in sign language.\"\n",
    "\n",
    "Case 1: Lemmatization only  \n",
    "Definitions:\n",
    "- a gesture that is part of a sign language  \n",
    "- make the sign of the cross over someone in order to call on God for protection; consecrate  \n",
    "- used of the language of the deaf  \n",
    "\n",
    "Case 2: Nouns only  \n",
    "Definitions:  \n",
    "- a gesture that is part of a sign language  \n",
    "- used of the language of the deaf  \n",
    "\n",
    "Case 3: Lemmatization & nouns  \n",
    "Definitions:  \n",
    "- a gesture that is part of a sign language  \n",
    "- used of the language of the deaf  \n",
    "\n",
    "In the above cases, filtering by only nouns (Case 2) selected the most appropriate definitions based on the context by focusing on nouns such as 'language' and 'gesture'. However, lemmatization is suitable for when words are not of their root form and in Case 1, the incorrect defintion was chosen due to preposition words 'for' and 'in' and article 'the'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signature\n",
    "\n",
    "I, -------NamChi Nguyen--------------, declare that the answers provided in this notebook are my own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
